import numpy as np
import open3d as o3d
import torch
from scipy.spatial.transform import Rotation as R
import rtde_receive
from pathlib import Path
import argparse

# cam2ee å˜æ¢çŸ©é˜µï¼ˆä»æ ‡å®šæ–‡ä»¶ï¼‰
cam2ee = np.array([
    [0.8031, -0.5953, -0.0242, -0.0937],
    [0.5945,  0.8034, -0.0350, -0.0752],
    [0.0402,  0.0137,  0.9991,  0.0400],
    [0,       0,       0,       1.0000]
])


def pose_to_matrix_xyzrxryrz(xyzrxryrz):
    """å°† UR çš„ xyz rx ry rz å§¿æ€è½¬ä¸º 4x4 é½æ¬¡çŸ©é˜µã€‚
    xyzrxryrz: [x, y, z, rx, ry, rz], ä½ç½®å•ä½ mï¼Œæ—‹è½¬ä¸ºè½´è§’(å¼§åº¦)
    """
    x, y, z, rx, ry, rz = xyzrxryrz
    T = np.eye(4)
    T[:3, :3] = R.from_rotvec([rx, ry, rz]).as_matrix()
    T[:3, 3] = [x, y, z]
    return T


def get_current_ee_to_base_transform(robot_ip="192.168.56.101", tcp_offset_pose=None):
    """
    ä»æœºå™¨äººè·å–å½“å‰çš„ TCP ä½å§¿ï¼Œå¹¶ï¼ˆå¯é€‰ï¼‰æ ¹æ®å·²é…ç½®çš„ TCP åç½®æ¢ç®—å‡ºæ³•å…°(EE)ä½å§¿ã€‚

    Args:
        robot_ip: æœºå™¨äºº IP
        tcp_offset_pose: æ³•å…°â†’TCP çš„ç›¸å¯¹ä½å§¿ [x, y, z, rx, ry, rz]ï¼ˆå•ä½ m, å¼§åº¦ï¼‰ã€‚
                         è‹¥æä¾›ï¼Œå°†ç”¨ baseâ†’TCP ä¸å…¶æ±‚é€†ç›¸ä¹˜å¾—åˆ° baseâ†’æ³•å…°ã€‚

    Returns:
        T_base_tcp:  baseâ†tcp 4x4
        T_base_ee:   baseâ†ee(æ³•å…°) 4x4ï¼ˆè‹¥æœªæä¾›åç½®ï¼Œåˆ™ç­‰äº T_base_tcpï¼‰
    """
    print(f"è¿æ¥æœºå™¨äºº: {robot_ip}")
    rtde = rtde_receive.RTDEReceiveInterface(robot_ip)
    
    # è·å–å½“å‰TCPå§¿æ€
    tcp_pose = rtde.getActualTCPPose()
    if tcp_pose is None:
        raise ValueError("æ— æ³•è·å–TCPå§¿æ€")
    
    position = tcp_pose[:3]
    rotvec = tcp_pose[3:]
    quaternion = R.from_rotvec(rotvec).as_quat()
    
    rtde.disconnect()
    
    print(f"âœ“ è·å–å½“å‰TCPå§¿æ€:")
    print(f"  ä½ç½®: {position}")
    print(f"  å››å…ƒæ•°: {quaternion}")

    # baseâ†tcp
    T_base_tcp = np.eye(4)
    T_base_tcp[:3, :3] = R.from_rotvec(rotvec).as_matrix()
    T_base_tcp[:3, 3] = position

    if tcp_offset_pose is not None:
        # æ³•å…°â†’TCP
        T_ee_tcp = pose_to_matrix_xyzrxryrz(tcp_offset_pose)
        # baseâ†ee = baseâ†tcp Â· tcpâ†ee = baseâ†tcp Â· (eeâ†tcp)^-1 = baseâ†tcp Â· (æ³•å…°â†’TCP)^-1
        T_base_ee = T_base_tcp @ np.linalg.inv(T_ee_tcp)
    else:
        print("âš  æœªæä¾› TCP åç½® (æ³•å…°â†’TCP)ï¼Œé»˜è®¤ EE=TCPã€‚è‹¥æ ‡å®šä½¿ç”¨æ³•å…°åæ ‡ï¼Œè¯·æä¾› --tcp-offset ä»¥ä¿®æ­£ EE ä½ç½®ã€‚")
        T_base_ee = T_base_tcp.copy()

    return T_base_tcp, T_base_ee


def get_cam_to_base_transform(robot_ip="192.168.56.101", tcp_offset_pose=None):
    """
    è®¡ç®—ç›¸æœºåœ¨base_linkåæ ‡ç³»ä¸‹çš„å˜æ¢çŸ©é˜µ
    è¿”å›:
        T_cam_base: ç›¸æœºåœ¨ base ä¸‹çš„ä½å§¿ (4x4)
        T_ee_base:  æœ«ç«¯åœ¨ base ä¸‹çš„ä½å§¿ (4x4)
    """
    # 1. è·å– baseâ†tcp ä¸ baseâ†ee(æ³•å…°) å˜æ¢
    T_base_tcp, T_base_ee = get_current_ee_to_base_transform(robot_ip, tcp_offset_pose)
    
    # 2. è®¡ç®— cam åœ¨ base ä¸‹çš„ä½å§¿: baseâ†cam = baseâ†ee Â· eeâ†cam
    T_cam_base = T_base_ee @ cam2ee
    
    cam_position = T_cam_base[:3, 3]
    cam_rotation = R.from_matrix(T_cam_base[:3, :3])
    cam_quaternion = cam_rotation.as_quat()
    
    print(f"\nâœ“ ç›¸æœºåœ¨base_linkçš„å˜æ¢:")
    print(f"  ä½ç½®: {cam_position}")
    print(f"  å››å…ƒæ•°: {cam_quaternion}")
    # åŒæ—¶æ‰“å° EE åœ¨ base ä¸‹çš„ä½å§¿ï¼Œä¾¿äºå¯¹ç…§
    ee_quat_print = R.from_matrix(T_base_ee[:3, :3]).as_quat()
    print(f"\nâœ“ æœ«ç«¯(EE)åœ¨base_linkçš„å˜æ¢:")
    print(f"  ä½ç½®: {T_base_ee[:3, 3]}")
    print(f"  å››å…ƒæ•°: {ee_quat_print}")
    
    return T_cam_base, T_base_ee


def transform_pointcloud_cam2base(input_ply, T_cam_base):
    """
    å°†ç‚¹äº‘ä»ç›¸æœºåæ ‡ç³»å˜æ¢åˆ°base_linkåæ ‡ç³»
    
    Args:
        input_ply: è¾“å…¥PLYæ–‡ä»¶è·¯å¾„
        T_cam_base: ç›¸æœºåœ¨base_linkä¸­çš„ä½å§¿ (4x4)
    
    Returns:
        points_base: å˜æ¢åçš„ç‚¹äº‘ (N, 3)
        colors: ç‚¹äº‘é¢œè‰² (N, 3)
    """
    print(f"\nåŠ è½½ç‚¹äº‘: {input_ply}")
    pcd = o3d.io.read_point_cloud(str(input_ply))
    
    points_cam = np.asarray(pcd.points)
    colors = np.asarray(pcd.colors) if pcd.has_colors() else None
    
    print(f"âœ“ åŸå§‹ç‚¹äº‘: {len(points_cam)} ç‚¹")
    print(f"  èŒƒå›´: {points_cam.min(axis=0)} ~ {points_cam.max(axis=0)}")
    
    # â­ å…³é”®ï¼šç‚¹çš„å˜æ¢éœ€è¦ç”¨é€†çŸ©é˜µï¼
    # T_cam_base: ç›¸æœºåæ ‡ç³»åœ¨baseä¸­çš„ä½å§¿
    # T_base_cam: ç”¨äºå˜æ¢ç‚¹ (ä»camåˆ°base)
    
    print(f"\nåº”ç”¨å˜æ¢: ç›¸æœºåæ ‡ç³» â†’ base_link")
    print(f"  T_cam_base (ç›¸æœºåœ¨baseä¸­çš„ä½å§¿):")
    print(T_cam_base)
    print(f"\n  T_base_cam (ç‚¹å˜æ¢çŸ©é˜µ, é€†çŸ©é˜µ):")
    
    # è½¬æ¢ä¸ºé½æ¬¡åæ ‡
    points_homo = np.hstack([points_cam, np.ones((points_cam.shape[0], 1))])
    
    # åº”ç”¨å˜æ¢
    points_base_homo = (T_cam_base @ points_homo.T).T
    points_base = points_base_homo[:, :3]
    
    print(f"\nâœ“ å˜æ¢åç‚¹äº‘:")
    print(f"  èŒƒå›´: {points_base.min(axis=0)} ~ {points_base.max(axis=0)}")
    
    return points_base, colors


def save_as_pytorch(points, colors, output_pt):
    """
    ä¿å­˜ä¸ºPyTorch .ptæ ¼å¼
    """
    output_pt = Path(output_pt)
    output_pt.parent.mkdir(parents=True, exist_ok=True)
    
    points_tensor = torch.from_numpy(points.astype(np.float32))
    torch.save(points_tensor, output_pt)
    
    print(f"\nâœ“ ä¿å­˜ç‚¹åæ ‡: {output_pt}")
    
    if colors is not None:
        colors_pt = output_pt.parent / 'colors.pt'
        colors_tensor = torch.from_numpy(colors.astype(np.float32))
        torch.save(colors_tensor, colors_pt)
        print(f"âœ“ ä¿å­˜ç‚¹é¢œè‰²: {colors_pt}")


def create_coordinate_frame(size=0.1, origin=[0, 0, 0]):
    """
    åˆ›å»ºåæ ‡ç³»å¯è§†åŒ–ï¼ˆXYZè½´ï¼‰
    """
    mesh_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(
        size=size, origin=origin)
    return mesh_frame


def visualize_result(points_base, colors, T_cam_base, T_ee_base):
    """
    å¯è§†åŒ–å˜æ¢åçš„ç‚¹äº‘å’Œåæ ‡ç³»
    """
    print(f"\nå¯è§†åŒ–ç»“æœ...")
    
    # 1. åˆ›å»ºç‚¹äº‘
    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(points_base)
    if colors is not None:
        pcd.colors = o3d.utility.Vector3dVector(colors)
    
    # 2. åˆ›å»ºbase_linkåæ ‡ç³»ï¼ˆåŸç‚¹ï¼‰
    base_frame = create_coordinate_frame(size=0.2, origin=[0, 0, 0])
    
    # 3. åˆ›å»ºç›¸æœºåæ ‡ç³»ï¼ˆåœ¨base_linkä¸­çš„ä½ç½®ï¼‰
    cam_position = T_cam_base[:3, 3]
    cam_frame = create_coordinate_frame(size=0.1, origin=cam_position)
    # åº”ç”¨æ—‹è½¬
    cam_frame.rotate(T_cam_base[:3, :3], center=cam_position)
    
    # 4. åˆ›å»ºæœ«ç«¯(EE)åæ ‡ç³»ï¼ˆåœ¨base_linkä¸­çš„ä½ç½®ï¼‰
    ee_position = T_ee_base[:3, 3]
    ee_frame = create_coordinate_frame(size=0.12, origin=ee_position)
    ee_frame.rotate(T_ee_base[:3, :3], center=ee_position)
    
    # 4. æ˜¾ç¤º
    print(f"\nå¯è§†åŒ–è¯´æ˜:")
    print(f"  ğŸ”´ å¤§åæ ‡ç³» (0.2m): base_link åŸç‚¹")
    print(f"  ğŸ”µ å°åæ ‡ç³» (0.1m): ç›¸æœºä½ç½® {cam_position}")
    print(f"  ğŸŸ¢ EE åæ ‡ç³» (0.12m): æœ«ç«¯ä½ç½® {ee_position}")
    print(f"  âšª ç‚¹äº‘: å˜æ¢åçš„ç‚¹äº‘ï¼ˆbase_linkåæ ‡ç³»ï¼‰")
    
    o3d.visualization.draw_geometries(
        [pcd, base_frame, cam_frame, ee_frame],
        window_name="ç‚¹äº‘å˜æ¢ç»“æœ (base_linkåæ ‡ç³»)",
        width=1920,
        height=1080,
        left=50,
        top=50
    )


def main():
    parser = argparse.ArgumentParser(description="å°†PLYç‚¹äº‘ä»ç›¸æœºåæ ‡ç³»å˜æ¢åˆ°base_link")
    parser.add_argument('--input', type=str, default='/home/hkcrc/DCIM/rs1105_3/cloud.ply')
    parser.add_argument('--output', type=str, default='points.pt')
    parser.add_argument('--robot_ip', type=str, default='192.168.56.101', help='æœºå™¨äººIP')
    parser.add_argument('--no-viz', action='store_true', help='ä¸æ˜¾ç¤ºå¯è§†åŒ–')
    parser.add_argument('--tcp-offset', type=float, nargs=6, default=None,
                        metavar=('x','y','z','rx','ry','rz'),
                        help='æ³•å…°â†’TCP çš„ç›¸å¯¹ä½å§¿ (ç±³, å¼§åº¦)ã€‚ç”¨äºä» TCP ä½å§¿è¿˜åŸæ³•å…°(EE)ä½å§¿ã€‚')
    
    args = parser.parse_args()
    
    print("="*80)
    print("ç‚¹äº‘åæ ‡å˜æ¢: ç›¸æœºåæ ‡ç³» â†’ base_link")
    print("="*80)
    
    # 1. è·å–cam2baseä¸ee2baseå˜æ¢ï¼ˆè‹¥æä¾› tcp åç½®åˆ™ç”¨äºè¿˜åŸæ³•å…°ä½å§¿ï¼‰
    T_cam_base, T_ee_base = get_cam_to_base_transform(args.robot_ip, args.tcp_offset)
    
    # 2. å˜æ¢ç‚¹äº‘
    points_base, colors = transform_pointcloud_cam2base(args.input, T_cam_base)
    
    # 3. ä¿å­˜ä¸º.pt
    save_as_pytorch(points_base, colors, args.output)
    
    # 4. å¯è§†åŒ–
    if not args.no_viz:
        visualize_result(points_base, colors, T_cam_base, T_ee_base)
    
    print("\n" + "="*80)
    print("âœ… å®Œæˆï¼")
    print("="*80)


if __name__ == "__main__":
    main()